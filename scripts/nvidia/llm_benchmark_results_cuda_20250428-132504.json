[
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 15.34,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 256,
        "avg_gpu_time_ms": 11693.467,
        "stddev_gpu_time_ms": 11.06,
        "tokens_per_sec": 21.89,
        "runs_gpu_time_ms": [
            11698.029,
            11701.517,
            11680.855
        ],
        "peak_gpu_memory_mb": 2962.95,
        "temp_before_c": 57,
        "temp_after_c": 60,
        "avg_temp_c": 58.5,
        "temp_increase_c": 3,
        "power_before_w": 37.03,
        "power_after_w": 37.98,
        "avg_power_w": 37.5,
        "output_text_preview": " German: 'Das Wetter ist heute sch\u00f6n.' \n\nThis sentence is in German, which is the language spoken in..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 15.34,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 148,
        "avg_gpu_time_ms": 6697.316,
        "stddev_gpu_time_ms": 97.433,
        "tokens_per_sec": 22.1,
        "runs_gpu_time_ms": [
            6805.484,
            6670.028,
            6616.436
        ],
        "peak_gpu_memory_mb": 2959.38,
        "temp_before_c": 60,
        "temp_after_c": 61,
        "avg_temp_c": 60.5,
        "temp_increase_c": 1,
        "power_before_w": 37.98,
        "power_after_w": 38.41,
        "avg_power_w": 38.2,
        "output_text_preview": " Quantum entanglement is a phenomenon in quantum mechanics where pairs or groups of particles intera..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 15.34,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 12,
        "output_tokens": 256,
        "avg_gpu_time_ms": 11483.665,
        "stddev_gpu_time_ms": 126.075,
        "tokens_per_sec": 22.29,
        "runs_gpu_time_ms": [
            11626.309,
            11387.152,
            11437.534
        ],
        "peak_gpu_memory_mb": 2962.88,
        "temp_before_c": 61,
        "temp_after_c": 62,
        "avg_temp_c": 61.5,
        "temp_increase_c": 1,
        "power_before_w": 38.41,
        "power_after_w": 38.8,
        "avg_power_w": 38.61,
        "output_text_preview": " def factorial(n): \n    if n == 0: \n        return 1\n    else: \n        return n * factorial(n-1) \n\n..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 15.34,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 256,
        "avg_gpu_time_ms": 11693.457,
        "stddev_gpu_time_ms": 177.578,
        "tokens_per_sec": 21.89,
        "runs_gpu_time_ms": [
            11677.129,
            11524.607,
            11878.635
        ],
        "peak_gpu_memory_mb": 2962.95,
        "temp_before_c": 62,
        "temp_after_c": 62,
        "avg_temp_c": 62.0,
        "temp_increase_c": 0,
        "power_before_w": 38.8,
        "power_after_w": 38.61,
        "avg_power_w": 38.7,
        "output_text_preview": " Inception is a 2010 science fiction film directed by Christopher Nolan. The movie follows a skilled..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 15.34,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 148,
        "avg_gpu_time_ms": 6698.434,
        "stddev_gpu_time_ms": 122.594,
        "tokens_per_sec": 22.09,
        "runs_gpu_time_ms": [
            6567.478,
            6810.464,
            6717.361
        ],
        "peak_gpu_memory_mb": 2959.44,
        "temp_before_c": 62,
        "temp_after_c": 62,
        "avg_temp_c": 62.0,
        "temp_increase_c": 0,
        "power_before_w": 38.61,
        "power_after_w": 39.63,
        "avg_power_w": 39.12,
        "output_text_preview": " Renewable energy sources are those that can be replenished naturally, such as solar, wind, and hydr..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.65,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 68,
        "avg_gpu_time_ms": 6701.497,
        "stddev_gpu_time_ms": 1297.443,
        "tokens_per_sec": 10.15,
        "runs_gpu_time_ms": [
            5908.141,
            5997.586,
            8198.766
        ],
        "peak_gpu_memory_mb": 1986.99,
        "temp_before_c": 54,
        "temp_after_c": 53,
        "avg_temp_c": 53.5,
        "temp_increase_c": -1,
        "power_before_w": 9.78,
        "power_after_w": 9.95,
        "avg_power_w": 9.86,
        "output_text_preview": "\n\nHere are a few options for translating this sentence:\n\n* **Das Wetter ist heute sch\u00f6n.** (This is ..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.65,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 11,
        "output_tokens": 256,
        "avg_gpu_time_ms": 23633.923,
        "stddev_gpu_time_ms": 303.208,
        "tokens_per_sec": 10.83,
        "runs_gpu_time_ms": [
            23423.588,
            23496.697,
            23981.484
        ],
        "peak_gpu_memory_mb": 1987.0,
        "temp_before_c": 53,
        "temp_after_c": 51,
        "avg_temp_c": 52.0,
        "temp_increase_c": -2,
        "power_before_w": 9.95,
        "power_after_w": 10.16,
        "avg_power_w": 10.06,
        "output_text_preview": "\n\nOkay, let's break down quantum entanglement. It's one of the most bizarre and fascinating aspects ..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.65,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 256,
        "avg_gpu_time_ms": 23401.24,
        "stddev_gpu_time_ms": 147.82,
        "tokens_per_sec": 10.94,
        "runs_gpu_time_ms": [
            23506.229,
            23465.295,
            23232.195
        ],
        "peak_gpu_memory_mb": 1987.0,
        "temp_before_c": 51,
        "temp_after_c": 50,
        "avg_temp_c": 50.5,
        "temp_increase_c": -1,
        "power_before_w": 10.16,
        "power_after_w": 10.0,
        "avg_power_w": 10.08,
        "output_text_preview": "\n\n```python\ndef factorial(n):\n  if n == 0:\n    return 1\n  else:\n    return n * factorial(n-1)\n```\n\n`..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.65,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 256,
        "avg_gpu_time_ms": 23366.472,
        "stddev_gpu_time_ms": 218.593,
        "tokens_per_sec": 10.96,
        "runs_gpu_time_ms": [
            23265.721,
            23617.271,
            23216.424
        ],
        "peak_gpu_memory_mb": 1987.0,
        "temp_before_c": 50,
        "temp_after_c": 50,
        "avg_temp_c": 50.0,
        "temp_increase_c": 0,
        "power_before_w": 10.0,
        "power_after_w": 11.07,
        "avg_power_w": 10.54,
        "output_text_preview": "\n\n\"Inception\" is a mind-bending heist film where a team of operatives, led by Robert Fischer, takes ..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.65,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 256,
        "avg_gpu_time_ms": 23545.682,
        "stddev_gpu_time_ms": 355.134,
        "tokens_per_sec": 10.87,
        "runs_gpu_time_ms": [
            23149.805,
            23650.986,
            23836.256
        ],
        "peak_gpu_memory_mb": 1987.0,
        "temp_before_c": 50,
        "temp_after_c": 50,
        "avg_temp_c": 50.0,
        "temp_increase_c": 0,
        "power_before_w": 11.07,
        "power_after_w": 9.69,
        "avg_power_w": 10.38,
        "output_text_preview": "\n\n**Renewable Energy Sources:**\n\n*   **Replenish naturally:** These sources are constantly replenish..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.48,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 10,
        "avg_gpu_time_ms": 255.797,
        "stddev_gpu_time_ms": 54.422,
        "tokens_per_sec": 39.09,
        "runs_gpu_time_ms": [
            207.012,
            314.493,
            245.885
        ],
        "peak_gpu_memory_mb": 2368.24,
        "temp_before_c": 59,
        "temp_after_c": 59,
        "avg_temp_c": 59.0,
        "temp_increase_c": 0,
        "power_before_w": 46.63,
        "power_after_w": 46.93,
        "avg_power_w": 46.78,
        "output_text_preview": " 'Die Wetterlage ist sch\u00f6n heute.'..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.48,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 256,
        "avg_gpu_time_ms": 5788.914,
        "stddev_gpu_time_ms": 451.63,
        "tokens_per_sec": 44.22,
        "runs_gpu_time_ms": [
            6310.325,
            5519.962,
            5536.456
        ],
        "peak_gpu_memory_mb": 2378.11,
        "temp_before_c": 59,
        "temp_after_c": 64,
        "avg_temp_c": 61.5,
        "temp_increase_c": 5,
        "power_before_w": 46.93,
        "power_after_w": 54.87,
        "avg_power_w": 50.9,
        "output_text_preview": " Imagine you have two toy cars that are connected by a spring. If you push one car, the other car wi..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.48,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 256,
        "avg_gpu_time_ms": 5555.297,
        "stddev_gpu_time_ms": 26.162,
        "tokens_per_sec": 46.08,
        "runs_gpu_time_ms": [
            5562.839,
            5526.192,
            5576.86
        ],
        "peak_gpu_memory_mb": 2378.08,
        "temp_before_c": 64,
        "temp_after_c": 65,
        "avg_temp_c": 64.5,
        "temp_increase_c": 1,
        "power_before_w": 54.87,
        "power_after_w": 55.03,
        "avg_power_w": 54.95,
        "output_text_preview": " The factorial of a number n, denoted by n!, is the product of all positive integers less than or eq..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.48,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 204,
        "avg_gpu_time_ms": 4411.088,
        "stddev_gpu_time_ms": 27.118,
        "tokens_per_sec": 46.25,
        "runs_gpu_time_ms": [
            4430.769,
            4422.339,
            4380.155
        ],
        "peak_gpu_memory_mb": 2375.29,
        "temp_before_c": 65,
        "temp_after_c": 66,
        "avg_temp_c": 65.5,
        "temp_increase_c": 1,
        "power_before_w": 55.03,
        "power_after_w": 55.46,
        "avg_power_w": 55.25,
        "output_text_preview": " Cobb, a skilled thief, is hired by a wealthy businessman to perform a task known as \"inception\" - p..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 256,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.48,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 16,
        "output_tokens": 256,
        "avg_gpu_time_ms": 5623.281,
        "stddev_gpu_time_ms": 134.965,
        "tokens_per_sec": 45.53,
        "runs_gpu_time_ms": [
            5550.077,
            5540.735,
            5779.031
        ],
        "peak_gpu_memory_mb": 2378.18,
        "temp_before_c": 66,
        "temp_after_c": 67,
        "avg_temp_c": 66.5,
        "temp_increase_c": 1,
        "power_before_w": 55.46,
        "power_after_w": 55.4,
        "avg_power_w": 55.43,
        "output_text_preview": "?\nThe main differences between renewable and non-renewable energy sources are:\n\n1. **Source of Energ..."
    }
]