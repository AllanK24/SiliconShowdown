[
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 14.87,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 20737.779,
        "stddev_gpu_time_ms": 2148.349,
        "tokens_per_sec": 24.69,
        "runs_gpu_time_ms": [
            20909.818,
            22794.936,
            18508.582
        ],
        "peak_gpu_memory_mb": 2971.88,
        "temp_before_c": 60,
        "temp_after_c": 64,
        "avg_temp_c": 62.0,
        "temp_increase_c": 4,
        "power_before_w": 38.17,
        "power_after_w": 47.77,
        "avg_power_w": 42.97,
        "output_text_preview": " German: 'Das Wetter ist heute sch\u00f6n.' \n\nThis sentence is in German, which is the language spoken in..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 14.87,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 148,
        "avg_gpu_time_ms": 5259.62,
        "stddev_gpu_time_ms": 30.944,
        "tokens_per_sec": 28.14,
        "runs_gpu_time_ms": [
            5294.378,
            5249.414,
            5235.069
        ],
        "peak_gpu_memory_mb": 2959.39,
        "temp_before_c": 64,
        "temp_after_c": 63,
        "avg_temp_c": 63.5,
        "temp_increase_c": -1,
        "power_before_w": 47.77,
        "power_after_w": 45.59,
        "avg_power_w": 46.68,
        "output_text_preview": " Quantum entanglement is a phenomenon in quantum mechanics where pairs or groups of particles intera..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 14.87,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 12,
        "output_tokens": 512,
        "avg_gpu_time_ms": 21521.802,
        "stddev_gpu_time_ms": 2728.97,
        "tokens_per_sec": 23.79,
        "runs_gpu_time_ms": [
            18377.477,
            22914.549,
            23273.381
        ],
        "peak_gpu_memory_mb": 2971.83,
        "temp_before_c": 63,
        "temp_after_c": 63,
        "avg_temp_c": 63.0,
        "temp_increase_c": 0,
        "power_before_w": 45.59,
        "power_after_w": 41.91,
        "avg_power_w": 43.75,
        "output_text_preview": " def factorial(n): \n    if n == 0: \n        return 1\n    else: \n        return n * factorial(n-1) \n\n..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 14.87,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 22843.475,
        "stddev_gpu_time_ms": 329.181,
        "tokens_per_sec": 22.41,
        "runs_gpu_time_ms": [
            22697.07,
            22612.895,
            23220.461
        ],
        "peak_gpu_memory_mb": 2971.88,
        "temp_before_c": 63,
        "temp_after_c": 63,
        "avg_temp_c": 63.0,
        "temp_increase_c": 0,
        "power_before_w": 41.91,
        "power_after_w": 41.92,
        "avg_power_w": 41.91,
        "output_text_preview": " Inception is a 2010 science fiction film directed by Christopher Nolan. The movie follows a skilled..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 14.87,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 148,
        "avg_gpu_time_ms": 5577.652,
        "stddev_gpu_time_ms": 688.318,
        "tokens_per_sec": 26.53,
        "runs_gpu_time_ms": [
            6370.691,
            5135.319,
            5226.946
        ],
        "peak_gpu_memory_mb": 2959.44,
        "temp_before_c": 63,
        "temp_after_c": 64,
        "avg_temp_c": 63.5,
        "temp_increase_c": 1,
        "power_before_w": 41.92,
        "power_after_w": 45.8,
        "avg_power_w": 43.86,
        "output_text_preview": " Renewable energy sources are those that can be replenished naturally, such as solar, wind, and hydr..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.3,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 68,
        "avg_gpu_time_ms": 8226.735,
        "stddev_gpu_time_ms": 2128.751,
        "tokens_per_sec": 8.27,
        "runs_gpu_time_ms": [
            6205.516,
            8025.907,
            10448.783
        ],
        "peak_gpu_memory_mb": 1993.19,
        "temp_before_c": 54,
        "temp_after_c": 54,
        "avg_temp_c": 54.0,
        "temp_increase_c": 0,
        "power_before_w": 11.88,
        "power_after_w": 16.55,
        "avg_power_w": 14.22,
        "output_text_preview": "\n\nHere are a few options for how to translate it, with slightly different nuances:\n\n*   **Das Wetter..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.3,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 11,
        "output_tokens": 512,
        "avg_gpu_time_ms": 40350.449,
        "stddev_gpu_time_ms": 5687.45,
        "tokens_per_sec": 12.69,
        "runs_gpu_time_ms": [
            45514.789,
            41281.723,
            34254.836
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 54,
        "temp_after_c": 53,
        "avg_temp_c": 53.5,
        "temp_increase_c": -1,
        "power_before_w": 16.55,
        "power_after_w": 15.21,
        "avg_power_w": 15.88,
        "output_text_preview": "\n\nOkay, let's break down quantum entanglement in a way that's easy to understand, without getting bo..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.3,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 512,
        "avg_gpu_time_ms": 42931.24,
        "stddev_gpu_time_ms": 1763.534,
        "tokens_per_sec": 11.93,
        "runs_gpu_time_ms": [
            44825.594,
            41337.055,
            42631.07
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 53,
        "temp_after_c": 51,
        "avg_temp_c": 52.0,
        "temp_increase_c": -2,
        "power_before_w": 15.21,
        "power_after_w": 11.47,
        "avg_power_w": 13.34,
        "output_text_preview": "\n\n```python\ndef factorial(n):\n  \"\"\"\n  Calculate the factorial of a non-negative integer.\n\n  Args:\n  ..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.3,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 40830.643,
        "stddev_gpu_time_ms": 4414.892,
        "tokens_per_sec": 12.54,
        "runs_gpu_time_ms": [
            45806.227,
            39304.074,
            37381.629
        ],
        "peak_gpu_memory_mb": 1993.2,
        "temp_before_c": 51,
        "temp_after_c": 51,
        "avg_temp_c": 51.0,
        "temp_increase_c": 0,
        "power_before_w": 11.4,
        "power_after_w": 10.39,
        "avg_power_w": 10.9,
        "output_text_preview": "\n\nThe movie 'Inception' revolves around a team of thieves who pull elaborate \"dream\" operations \u2013 \"i..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.3,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 333,
        "avg_gpu_time_ms": 30399.223,
        "stddev_gpu_time_ms": 2913.477,
        "tokens_per_sec": 10.95,
        "runs_gpu_time_ms": [
            28522.371,
            33755.586,
            28919.713
        ],
        "peak_gpu_memory_mb": 1993.2,
        "temp_before_c": 51,
        "temp_after_c": 54,
        "avg_temp_c": 52.5,
        "temp_increase_c": 3,
        "power_before_w": 10.39,
        "power_after_w": 18.65,
        "avg_power_w": 14.52,
        "output_text_preview": "\n\n**Renewable Energy Sources:**\n\n*   **Source:** These are naturally replenished on a human timescal..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.63,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 10,
        "avg_gpu_time_ms": 257.832,
        "stddev_gpu_time_ms": 13.865,
        "tokens_per_sec": 38.78,
        "runs_gpu_time_ms": [
            251.883,
            247.935,
            273.679
        ],
        "peak_gpu_memory_mb": 2368.24,
        "temp_before_c": 62,
        "temp_after_c": 61,
        "avg_temp_c": 61.5,
        "temp_increase_c": -1,
        "power_before_w": 45.66,
        "power_after_w": 47.97,
        "avg_power_w": 46.82,
        "output_text_preview": " 'Die Wetterlage ist sch\u00f6n heute.'..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.63,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 399,
        "avg_gpu_time_ms": 10064.703,
        "stddev_gpu_time_ms": 62.99,
        "tokens_per_sec": 39.64,
        "runs_gpu_time_ms": [
            9991.975,
            10100.266,
            10101.869
        ],
        "peak_gpu_memory_mb": 2383.14,
        "temp_before_c": 61,
        "temp_after_c": 63,
        "avg_temp_c": 62.0,
        "temp_increase_c": 2,
        "power_before_w": 47.97,
        "power_after_w": 50.81,
        "avg_power_w": 49.39,
        "output_text_preview": " Imagine you have two toy cars that are connected by a spring. If you push one car, the other car wi..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.63,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 507,
        "avg_gpu_time_ms": 12833.549,
        "stddev_gpu_time_ms": 65.021,
        "tokens_per_sec": 39.51,
        "runs_gpu_time_ms": [
            12847.0,
            12762.854,
            12890.793
        ],
        "peak_gpu_memory_mb": 2387.06,
        "temp_before_c": 63,
        "temp_after_c": 66,
        "avg_temp_c": 64.5,
        "temp_increase_c": 3,
        "power_before_w": 50.81,
        "power_after_w": 51.48,
        "avg_power_w": 51.15,
        "output_text_preview": " The factorial of a number n, denoted by n!, is the product of all positive integers less than or eq..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.63,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 204,
        "avg_gpu_time_ms": 5348.599,
        "stddev_gpu_time_ms": 93.779,
        "tokens_per_sec": 38.14,
        "runs_gpu_time_ms": [
            5424.313,
            5377.786,
            5243.696
        ],
        "peak_gpu_memory_mb": 2375.29,
        "temp_before_c": 66,
        "temp_after_c": 65,
        "avg_temp_c": 65.5,
        "temp_increase_c": -1,
        "power_before_w": 51.48,
        "power_after_w": 50.82,
        "avg_power_w": 51.15,
        "output_text_preview": " Cobb, a skilled thief, is hired by a wealthy businessman to perform a task known as \"inception\" - p..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.63,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 16,
        "output_tokens": 512,
        "avg_gpu_time_ms": 12940.242,
        "stddev_gpu_time_ms": 574.586,
        "tokens_per_sec": 39.57,
        "runs_gpu_time_ms": [
            12401.764,
            12873.804,
            13545.159
        ],
        "peak_gpu_memory_mb": 2387.38,
        "temp_before_c": 65,
        "temp_after_c": 66,
        "avg_temp_c": 65.5,
        "temp_increase_c": 1,
        "power_before_w": 50.82,
        "power_after_w": 50.8,
        "avg_power_w": 50.81,
        "output_text_preview": "?\nThe main differences between renewable and non-renewable energy sources are:\n\n1. **Source of Energ..."
    }
]