[
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 94.21,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 22928.159,
        "stddev_gpu_time_ms": 138.567,
        "tokens_per_sec": 22.33,
        "runs_gpu_time_ms": [
            23025.947,
            22988.941,
            22769.588
        ],
        "peak_gpu_memory_mb": 2971.88,
        "temp_before_c": 64,
        "temp_after_c": 64,
        "avg_temp_c": 64.0,
        "temp_increase_c": 0,
        "power_before_w": 38.87,
        "power_after_w": 43.35,
        "avg_power_w": 41.11,
        "output_text_preview": " German: 'Das Wetter ist heute sch\u00f6n.' \n\nThis sentence is in German, which is the language spoken in..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 94.21,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 148,
        "avg_gpu_time_ms": 6751.916,
        "stddev_gpu_time_ms": 78.494,
        "tokens_per_sec": 21.92,
        "runs_gpu_time_ms": [
            6662.313,
            6808.54,
            6784.896
        ],
        "peak_gpu_memory_mb": 2959.39,
        "temp_before_c": 64,
        "temp_after_c": 63,
        "avg_temp_c": 63.5,
        "temp_increase_c": -1,
        "power_before_w": 43.35,
        "power_after_w": 35.84,
        "avg_power_w": 39.6,
        "output_text_preview": " Quantum entanglement is a phenomenon in quantum mechanics where pairs or groups of particles intera..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 94.21,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 12,
        "output_tokens": 512,
        "avg_gpu_time_ms": 22867.089,
        "stddev_gpu_time_ms": 500.006,
        "tokens_per_sec": 22.39,
        "runs_gpu_time_ms": [
            23236.572,
            22298.137,
            23066.557
        ],
        "peak_gpu_memory_mb": 2971.83,
        "temp_before_c": 63,
        "temp_after_c": 64,
        "avg_temp_c": 63.5,
        "temp_increase_c": 1,
        "power_before_w": 35.84,
        "power_after_w": 72.52,
        "avg_power_w": 54.18,
        "output_text_preview": " def factorial(n): \n    if n == 0: \n        return 1\n    else: \n        return n * factorial(n-1) \n\n..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 94.21,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 23288.348,
        "stddev_gpu_time_ms": 200.4,
        "tokens_per_sec": 21.99,
        "runs_gpu_time_ms": [
            23057.816,
            23420.977,
            23386.25
        ],
        "peak_gpu_memory_mb": 2971.88,
        "temp_before_c": 64,
        "temp_after_c": 64,
        "avg_temp_c": 64.0,
        "temp_increase_c": 0,
        "power_before_w": 72.52,
        "power_after_w": 41.58,
        "avg_power_w": 57.05,
        "output_text_preview": " Inception is a 2010 science fiction film directed by Christopher Nolan. The movie follows a skilled..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 94.21,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 148,
        "avg_gpu_time_ms": 6699.747,
        "stddev_gpu_time_ms": 66.19,
        "tokens_per_sec": 22.09,
        "runs_gpu_time_ms": [
            6706.764,
            6630.327,
            6762.149
        ],
        "peak_gpu_memory_mb": 2959.44,
        "temp_before_c": 64,
        "temp_after_c": 63,
        "avg_temp_c": 63.5,
        "temp_increase_c": -1,
        "power_before_w": 41.58,
        "power_after_w": 37.59,
        "avg_power_w": 39.59,
        "output_text_preview": " Renewable energy sources are those that can be replenished naturally, such as solar, wind, and hydr..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 55.46,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 56,
        "avg_gpu_time_ms": 6792.304,
        "stddev_gpu_time_ms": 1778.027,
        "tokens_per_sec": 8.24,
        "runs_gpu_time_ms": [
            5287.046,
            8754.076,
            6335.789
        ],
        "peak_gpu_memory_mb": 1993.19,
        "temp_before_c": 54,
        "temp_after_c": 54,
        "avg_temp_c": 54.0,
        "temp_increase_c": 0,
        "power_before_w": 8.99,
        "power_after_w": 10.22,
        "avg_power_w": 9.61,
        "output_text_preview": "\n\nHere are a few options, ranging from formal to informal:\n\n* **Formal:** \"Das Wetter ist heute wund..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 55.46,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 11,
        "output_tokens": 512,
        "avg_gpu_time_ms": 47245.013,
        "stddev_gpu_time_ms": 577.224,
        "tokens_per_sec": 10.84,
        "runs_gpu_time_ms": [
            47117.098,
            46742.477,
            47875.465
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 54,
        "temp_after_c": 54,
        "avg_temp_c": 54.0,
        "temp_increase_c": 0,
        "power_before_w": 10.22,
        "power_after_w": 10.29,
        "avg_power_w": 10.26,
        "output_text_preview": "\n\nOkay, let's break down quantum entanglement. It\u2019s one of the weirdest and most fascinating concept..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 55.46,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 512,
        "avg_gpu_time_ms": 43550.608,
        "stddev_gpu_time_ms": 5261.256,
        "tokens_per_sec": 11.76,
        "runs_gpu_time_ms": [
            46485.84,
            37476.57,
            46689.414
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 54,
        "temp_after_c": 55,
        "avg_temp_c": 54.5,
        "temp_increase_c": 1,
        "power_before_w": 10.29,
        "power_after_w": 10.59,
        "avg_power_w": 10.44,
        "output_text_preview": "\n\n```python\ndef factorial(n):\n  \"\"\"\n  Calculate the factorial of a number.\n\n  Args:\n    n: An intege..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 55.46,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 43210.129,
        "stddev_gpu_time_ms": 4224.745,
        "tokens_per_sec": 11.85,
        "runs_gpu_time_ms": [
            47636.844,
            39221.492,
            42772.051
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 55,
        "temp_after_c": 55,
        "avg_temp_c": 55.0,
        "temp_increase_c": 0,
        "power_before_w": 10.59,
        "power_after_w": 9.43,
        "avg_power_w": 10.01,
        "output_text_preview": "\n\nHere's a summary of the main plot points of Christopher Nolan's 'Inception':\n\n1. **The Setup:** Do..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 55.46,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 264,
        "avg_gpu_time_ms": 33802.552,
        "stddev_gpu_time_ms": 11995.734,
        "tokens_per_sec": 7.81,
        "runs_gpu_time_ms": [
            24384.227,
            29715.75,
            47307.68
        ],
        "peak_gpu_memory_mb": 1993.2,
        "temp_before_c": 55,
        "temp_after_c": 55,
        "avg_temp_c": 55.0,
        "temp_increase_c": 0,
        "power_before_w": 9.43,
        "power_after_w": 10.19,
        "avg_power_w": 9.81,
        "output_text_preview": "\n\n| Feature        | Renewable Energy Sources | Non-Renewable Energy Sources |\n|----------------|---..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 68.32,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 10,
        "avg_gpu_time_ms": 277.313,
        "stddev_gpu_time_ms": 3.581,
        "tokens_per_sec": 36.06,
        "runs_gpu_time_ms": [
            276.478,
            281.238,
            274.223
        ],
        "peak_gpu_memory_mb": 2368.24,
        "temp_before_c": 62,
        "temp_after_c": 62,
        "avg_temp_c": 62.0,
        "temp_increase_c": 0,
        "power_before_w": 52.99,
        "power_after_w": 45.07,
        "avg_power_w": 49.03,
        "output_text_preview": " 'Die Wetterlage ist sch\u00f6n heute.'..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 68.32,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 399,
        "avg_gpu_time_ms": 10407.331,
        "stddev_gpu_time_ms": 214.312,
        "tokens_per_sec": 38.34,
        "runs_gpu_time_ms": [
            10282.868,
            10284.329,
            10654.796
        ],
        "peak_gpu_memory_mb": 2383.14,
        "temp_before_c": 62,
        "temp_after_c": 66,
        "avg_temp_c": 64.0,
        "temp_increase_c": 4,
        "power_before_w": 45.07,
        "power_after_w": 44.49,
        "avg_power_w": 44.78,
        "output_text_preview": " Imagine you have two toy cars that are connected by a spring. If you push one car, the other car wi..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 68.32,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 507,
        "avg_gpu_time_ms": 13526.093,
        "stddev_gpu_time_ms": 205.931,
        "tokens_per_sec": 37.48,
        "runs_gpu_time_ms": [
            13719.133,
            13309.327,
            13549.82
        ],
        "peak_gpu_memory_mb": 2387.06,
        "temp_before_c": 66,
        "temp_after_c": 68,
        "avg_temp_c": 67.0,
        "temp_increase_c": 2,
        "power_before_w": 44.49,
        "power_after_w": 47.87,
        "avg_power_w": 46.18,
        "output_text_preview": " The factorial of a number n, denoted by n!, is the product of all positive integers less than or eq..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 68.32,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 204,
        "avg_gpu_time_ms": 5432.367,
        "stddev_gpu_time_ms": 128.39,
        "tokens_per_sec": 37.55,
        "runs_gpu_time_ms": [
            5549.124,
            5453.109,
            5294.869
        ],
        "peak_gpu_memory_mb": 2375.29,
        "temp_before_c": 68,
        "temp_after_c": 68,
        "avg_temp_c": 68.0,
        "temp_increase_c": 0,
        "power_before_w": 47.87,
        "power_after_w": 47.72,
        "avg_power_w": 47.79,
        "output_text_preview": " Cobb, a skilled thief, is hired by a wealthy businessman to perform a task known as \"inception\" - p..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 68.32,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 16,
        "output_tokens": 512,
        "avg_gpu_time_ms": 13112.148,
        "stddev_gpu_time_ms": 197.997,
        "tokens_per_sec": 39.05,
        "runs_gpu_time_ms": [
            13143.474,
            12900.355,
            13292.614
        ],
        "peak_gpu_memory_mb": 2387.38,
        "temp_before_c": 68,
        "temp_after_c": 66,
        "avg_temp_c": 67.0,
        "temp_increase_c": -2,
        "power_before_w": 47.72,
        "power_after_w": 48.35,
        "avg_power_w": 48.04,
        "output_text_preview": "?\nThe main differences between renewable and non-renewable energy sources are:\n\n1. **Source of Energ..."
    }
]