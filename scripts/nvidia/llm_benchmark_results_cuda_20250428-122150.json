[
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 5.69,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 22914.264,
        "stddev_gpu_time_ms": 176.996,
        "tokens_per_sec": 22.34,
        "runs_gpu_time_ms": [
            23104.865,
            22755.082,
            22882.846
        ],
        "peak_gpu_memory_mb": 2971.88,
        "temp_before_c": 59,
        "temp_after_c": 62,
        "avg_temp_c": 60.5,
        "temp_increase_c": 3,
        "power_before_w": 39.09,
        "power_after_w": 40.55,
        "avg_power_w": 39.82,
        "output_text_preview": " German: 'Das Wetter ist heute sch\u00f6n.' \n\nThis sentence is in German, which is the language spoken in..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 5.69,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 148,
        "avg_gpu_time_ms": 5785.576,
        "stddev_gpu_time_ms": 458.967,
        "tokens_per_sec": 25.58,
        "runs_gpu_time_ms": [
            6241.302,
            5323.435,
            5791.991
        ],
        "peak_gpu_memory_mb": 2959.39,
        "temp_before_c": 62,
        "temp_after_c": 61,
        "avg_temp_c": 61.5,
        "temp_increase_c": -1,
        "power_before_w": 40.55,
        "power_after_w": 37.42,
        "avg_power_w": 38.98,
        "output_text_preview": " Quantum entanglement is a phenomenon in quantum mechanics where pairs or groups of particles intera..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 5.69,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 12,
        "output_tokens": 512,
        "avg_gpu_time_ms": 22753.101,
        "stddev_gpu_time_ms": 146.46,
        "tokens_per_sec": 22.5,
        "runs_gpu_time_ms": [
            22699.35,
            22918.842,
            22641.111
        ],
        "peak_gpu_memory_mb": 2971.83,
        "temp_before_c": 61,
        "temp_after_c": 61,
        "avg_temp_c": 61.0,
        "temp_increase_c": 0,
        "power_before_w": 37.42,
        "power_after_w": 40.29,
        "avg_power_w": 38.85,
        "output_text_preview": " def factorial(n): \n    if n == 0: \n        return 1\n    else: \n        return n * factorial(n-1) \n\n..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 5.69,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 20697.568,
        "stddev_gpu_time_ms": 2314.188,
        "tokens_per_sec": 24.74,
        "runs_gpu_time_ms": [
            22290.461,
            21759.207,
            18043.035
        ],
        "peak_gpu_memory_mb": 2971.88,
        "temp_before_c": 61,
        "temp_after_c": 63,
        "avg_temp_c": 62.0,
        "temp_increase_c": 2,
        "power_before_w": 40.29,
        "power_after_w": 46.59,
        "avg_power_w": 43.44,
        "output_text_preview": " Inception is a 2010 science fiction film directed by Christopher Nolan. The movie follows a skilled..."
    },
    {
        "model_id": "Qwen/Qwen2.5-1.5B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 5.69,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 148,
        "avg_gpu_time_ms": 5239.533,
        "stddev_gpu_time_ms": 51.854,
        "tokens_per_sec": 28.25,
        "runs_gpu_time_ms": [
            5298.24,
            5220.374,
            5199.986
        ],
        "peak_gpu_memory_mb": 2959.44,
        "temp_before_c": 63,
        "temp_after_c": 63,
        "avg_temp_c": 63.0,
        "temp_increase_c": 0,
        "power_before_w": 46.59,
        "power_after_w": 44.43,
        "avg_power_w": 45.51,
        "output_text_preview": " Renewable energy sources are those that can be replenished naturally, such as solar, wind, and hydr..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.43,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 85,
        "avg_gpu_time_ms": 8213.652,
        "stddev_gpu_time_ms": 1925.099,
        "tokens_per_sec": 10.35,
        "runs_gpu_time_ms": [
            6094.468,
            8692.039,
            9854.45
        ],
        "peak_gpu_memory_mb": 1993.19,
        "temp_before_c": 53,
        "temp_after_c": 53,
        "avg_temp_c": 53.0,
        "temp_increase_c": 0,
        "power_before_w": 12.04,
        "power_after_w": 9.83,
        "avg_power_w": 10.94,
        "output_text_preview": "\n\nHere are a few options, with slightly different nuances:\n\n* **Das Wetter ist heute sch\u00f6n.** (Most ..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.43,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 11,
        "output_tokens": 512,
        "avg_gpu_time_ms": 41581.085,
        "stddev_gpu_time_ms": 6474.619,
        "tokens_per_sec": 12.31,
        "runs_gpu_time_ms": [
            47656.719,
            42316.289,
            34770.246
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 53,
        "temp_after_c": 52,
        "avg_temp_c": 52.5,
        "temp_increase_c": -1,
        "power_before_w": 9.83,
        "power_after_w": 13.3,
        "avg_power_w": 11.56,
        "output_text_preview": "\n\nOkay, let's break down quantum entanglement. It's one of the weirdest and most fascinating concept..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.43,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 512,
        "avg_gpu_time_ms": 26705.997,
        "stddev_gpu_time_ms": 15837.666,
        "tokens_per_sec": 19.17,
        "runs_gpu_time_ms": [
            34954.359,
            36717.059,
            8446.574
        ],
        "peak_gpu_memory_mb": 1993.2,
        "temp_before_c": 52,
        "temp_after_c": 54,
        "avg_temp_c": 53.0,
        "temp_increase_c": 2,
        "power_before_w": 13.3,
        "power_after_w": 13.82,
        "avg_power_w": 13.56,
        "output_text_preview": "\n\n```python\ndef factorial(n):\n  \"\"\"\n  Calculates the factorial of a non-negative integer.\n\n  Args:\n ..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.43,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 512,
        "avg_gpu_time_ms": 39217.415,
        "stddev_gpu_time_ms": 6230.786,
        "tokens_per_sec": 13.06,
        "runs_gpu_time_ms": [
            34424.949,
            36966.402,
            46260.895
        ],
        "peak_gpu_memory_mb": 1993.21,
        "temp_before_c": 54,
        "temp_after_c": 51,
        "avg_temp_c": 52.5,
        "temp_increase_c": -3,
        "power_before_w": 13.82,
        "power_after_w": 10.23,
        "avg_power_w": 12.03,
        "output_text_preview": "\n\n**Here's a breakdown of the key events:**\n\n* **The Core Concept:** \"Inception\" revolves around the..."
    },
    {
        "model_id": "google/gemma-3-1b-it",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.43,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 337,
        "avg_gpu_time_ms": 36506.423,
        "stddev_gpu_time_ms": 8980.093,
        "tokens_per_sec": 9.23,
        "runs_gpu_time_ms": [
            30534.914,
            46833.695,
            32150.66
        ],
        "peak_gpu_memory_mb": 1993.2,
        "temp_before_c": 51,
        "temp_after_c": 49,
        "avg_temp_c": 50.0,
        "temp_increase_c": -2,
        "power_before_w": 10.23,
        "power_after_w": 9.91,
        "avg_power_w": 10.07,
        "output_text_preview": "\n\n**Renewable Energy Sources**\n\n*   **Source:** Naturally replenished.\n*   **Examples:** Solar, wind..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.56,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Translate the following sentence to German: 'The weather is beautiful today.'",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 10,
        "avg_gpu_time_ms": 271.598,
        "stddev_gpu_time_ms": 26.796,
        "tokens_per_sec": 36.82,
        "runs_gpu_time_ms": [
            297.774,
            272.797,
            244.222
        ],
        "peak_gpu_memory_mb": 2368.24,
        "temp_before_c": 59,
        "temp_after_c": 59,
        "avg_temp_c": 59.0,
        "temp_increase_c": 0,
        "power_before_w": 44.79,
        "power_after_w": 44.75,
        "avg_power_w": 44.77,
        "output_text_preview": " 'Die Wetterlage ist sch\u00f6n heute.'..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.56,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Explain the concept of quantum entanglement in simple terms.",
        "status": "success",
        "error_message": null,
        "input_tokens": 14,
        "output_tokens": 399,
        "avg_gpu_time_ms": 10341.937,
        "stddev_gpu_time_ms": 117.244,
        "tokens_per_sec": 38.58,
        "runs_gpu_time_ms": [
            10215.196,
            10364.089,
            10446.524
        ],
        "peak_gpu_memory_mb": 2383.14,
        "temp_before_c": 59,
        "temp_after_c": 62,
        "avg_temp_c": 60.5,
        "temp_increase_c": 3,
        "power_before_w": 44.75,
        "power_after_w": 50.1,
        "avg_power_w": 47.43,
        "output_text_preview": " Imagine you have two toy cars that are connected by a spring. If you push one car, the other car wi..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.56,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Write a python function that calculates the factorial of a number.",
        "status": "success",
        "error_message": null,
        "input_tokens": 13,
        "output_tokens": 507,
        "avg_gpu_time_ms": 13355.337,
        "stddev_gpu_time_ms": 74.076,
        "tokens_per_sec": 37.96,
        "runs_gpu_time_ms": [
            13345.371,
            13433.891,
            13286.748
        ],
        "peak_gpu_memory_mb": 2387.06,
        "temp_before_c": 62,
        "temp_after_c": 63,
        "avg_temp_c": 62.5,
        "temp_increase_c": 1,
        "power_before_w": 50.1,
        "power_after_w": 49.09,
        "avg_power_w": 49.6,
        "output_text_preview": " The factorial of a number n, denoted by n!, is the product of all positive integers less than or eq..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.56,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "Summarize the main plot points of the movie 'Inception'.",
        "status": "success",
        "error_message": null,
        "input_tokens": 15,
        "output_tokens": 204,
        "avg_gpu_time_ms": 5373.032,
        "stddev_gpu_time_ms": 94.459,
        "tokens_per_sec": 37.97,
        "runs_gpu_time_ms": [
            5468.95,
            5280.102,
            5370.043
        ],
        "peak_gpu_memory_mb": 2375.29,
        "temp_before_c": 63,
        "temp_after_c": 64,
        "avg_temp_c": 63.5,
        "temp_increase_c": 1,
        "power_before_w": 49.09,
        "power_after_w": 48.41,
        "avg_power_w": 48.75,
        "output_text_preview": " Cobb, a skilled thief, is hired by a wealthy businessman to perform a task known as \"inception\" - p..."
    },
    {
        "model_id": "meta-llama/Llama-3.2-1B-Instruct",
        "benchmark_dtype": "torch.float16",
        "batch_size": 1,
        "generation_config": {
            "max_length": 20,
            "max_new_tokens": 512,
            "min_length": 0,
            "min_new_tokens": null,
            "early_stopping": false,
            "max_time": null,
            "stop_strings": null,
            "do_sample": false,
            "num_beams": 1,
            "num_beam_groups": 1,
            "penalty_alpha": null,
            "dola_layers": null,
            "use_cache": true,
            "cache_implementation": null,
            "cache_config": null,
            "return_legacy_cache": null,
            "prefill_chunk_size": null,
            "temperature": 1.0,
            "top_k": 50,
            "top_p": 1.0,
            "min_p": null,
            "typical_p": 1.0,
            "epsilon_cutoff": 0.0,
            "eta_cutoff": 0.0,
            "diversity_penalty": 0.0,
            "repetition_penalty": 1.0,
            "encoder_repetition_penalty": 1.0,
            "length_penalty": 1.0,
            "no_repeat_ngram_size": 0,
            "bad_words_ids": null,
            "force_words_ids": null,
            "renormalize_logits": false,
            "constraints": null,
            "forced_bos_token_id": null,
            "forced_eos_token_id": null,
            "remove_invalid_values": false,
            "exponential_decay_length_penalty": null,
            "suppress_tokens": null,
            "begin_suppress_tokens": null,
            "forced_decoder_ids": null,
            "sequence_bias": null,
            "token_healing": false,
            "guidance_scale": null,
            "low_memory": null,
            "watermarking_config": null,
            "num_return_sequences": 1,
            "output_attentions": false,
            "output_hidden_states": false,
            "output_scores": false,
            "output_logits": null,
            "return_dict_in_generate": false,
            "pad_token_id": null,
            "bos_token_id": null,
            "eos_token_id": null,
            "encoder_no_repeat_ngram_size": 0,
            "decoder_start_token_id": null,
            "is_assistant": false,
            "num_assistant_tokens": 20,
            "num_assistant_tokens_schedule": "constant",
            "assistant_confidence_threshold": 0.4,
            "prompt_lookup_num_tokens": null,
            "max_matching_ngram_size": null,
            "assistant_early_exit": null,
            "assistant_lookbehind": 10,
            "target_lookbehind": 10,
            "disable_compile": false,
            "generation_kwargs": {},
            "_from_model_config": false,
            "transformers_version": "4.51.3"
        },
        "num_global_warmup_runs": 3,
        "num_timed_runs_per_prompt": 3,
        "model_load_time_s": 2.56,
        "accelerator_used": "CUDA",
        "quantization_method": "None",
        "prompt": "What are the main differences between renewable and non-renewable energy sources?",
        "status": "success",
        "error_message": null,
        "input_tokens": 16,
        "output_tokens": 512,
        "avg_gpu_time_ms": 13286.003,
        "stddev_gpu_time_ms": 66.913,
        "tokens_per_sec": 38.54,
        "runs_gpu_time_ms": [
            13362.231,
            13258.812,
            13236.966
        ],
        "peak_gpu_memory_mb": 2387.38,
        "temp_before_c": 64,
        "temp_after_c": 65,
        "avg_temp_c": 64.5,
        "temp_increase_c": 1,
        "power_before_w": 48.41,
        "power_after_w": 49.88,
        "avg_power_w": 49.15,
        "output_text_preview": "?\nThe main differences between renewable and non-renewable energy sources are:\n\n1. **Source of Energ..."
    }
]